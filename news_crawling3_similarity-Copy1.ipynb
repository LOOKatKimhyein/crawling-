{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "조선일보 뉴스 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    with open(filename, 'r',encoding = 'utf-8') as f:\n",
    "        data = [line.split('\\t') for line in f.read().splitlines()]\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "import pickle\n",
    "# load\n",
    "with open('/content/hikim/traintestdata/train_docs_save.txt', 'rb') as rd:\n",
    "    train_docs1 = pickle.load(rd)\n",
    "    \n",
    "with open('/content/hikim/traintestdata/test_docs_save.txt', 'rb') as rd:\n",
    "    test_docs1 = pickle.load(rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from gensim import corpora,models,similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from gensim.models import doc2vec\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_train_docs = [TaggedDocument(d, [c]) for d, c in train_docs1]\n",
    "tagged_test_docs = [TaggedDocument(d, [c]) for d, c in test_docs1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 사전 구축\n",
    "doc_vectorizer = doc2vec.Doc2Vec(\n",
    "    dm=0,            # PV-DBOW / default 1\n",
    "    dbow_words=0,    # w2v simultaneous with DBOW d2v / default 0\n",
    "    window=5,        # distance between the predicted word and context words \n",
    "    size=500,        # vector size \n",
    "    alpha=0.025,     # learning-rate\n",
    "    \n",
    "    seed=1234,\n",
    "    \n",
    "    min_count=10,    # 너무 적게나온 단어 제거\n",
    "    min_alpha=0.025, # min learning-rate\n",
    "    workers=cores,   # 멀티 쓰레드\n",
    "    sample=1e-5,    #  Subsampling Frequent Words 너무 많이 나온단어 빈도 줄이기\n",
    "    hs=0,          # hierarchical softmax / default 0\n",
    "    negative=5   # negative sampling / default 5\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12567"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tagged_train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectorizer.build_vocab(tagged_train_docs)\n",
    "#한번만 돌려야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow,d500,n5,mc10,s1e-05,t24)\n"
     ]
    }
   ],
   "source": [
    "print(str(doc_vectorizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gensim 문서를 보면 벡터화하기 전에 로그값을 출력하도록 명시하고 있다고 한다.\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "#벡터화를 위한 학습실행\n",
    "for epoch in range(10):\n",
    "    doc_vectorizer.train(tagged_train_docs, total_examples=doc_vectorizer.corpus_count, epochs = 5)\n",
    "    doc_vectorizer.alpha -= 0.002  # decrease the learning rate\n",
    "    \n",
    "    doc_vectorizer.min_alpha = doc_vectorizer.alpha  # fix the learning rate, no decay\n",
    "    \n",
    "end = time()\n",
    "print(\"During Time : {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save\n",
    "modelfile = 'H_doc2vec.model'\n",
    "doc_vectorizer.save(modelfile)\n",
    "#doc_vectorizer.save_word2vec_format(word2vec_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-26 13:44:10,480 : INFO : loading Doc2Vec object from H_doc2vec.model\n",
      "2019-03-26 13:44:10,979 : INFO : loading vocabulary recursively from H_doc2vec.model.vocabulary.* with mmap=None\n",
      "2019-03-26 13:44:10,980 : INFO : loading trainables recursively from H_doc2vec.model.trainables.* with mmap=None\n",
      "2019-03-26 13:44:10,980 : INFO : loading syn1neg from H_doc2vec.model.trainables.syn1neg.npy with mmap=None\n",
      "2019-03-26 13:44:11,080 : INFO : loading wv recursively from H_doc2vec.model.wv.* with mmap=None\n",
      "2019-03-26 13:44:11,081 : INFO : loading vectors from H_doc2vec.model.wv.vectors.npy with mmap=None\n",
      "2019-03-26 13:44:11,189 : INFO : loading docvecs recursively from H_doc2vec.model.docvecs.* with mmap=None\n",
      "2019-03-26 13:44:11,190 : INFO : loaded H_doc2vec.model\n"
     ]
    }
   ],
   "source": [
    "#load model\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "doc_vectorizer = Doc2Vec.load(modelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-26 13:39:38,458 : INFO : collecting all words and their counts\n",
      "2019-03-26 13:39:38,460 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2019-03-26 13:39:39,535 : INFO : PROGRESS: at example #10000, processed 4587497 words (4271186/s), 75414 word types, 9 tags\n",
      "2019-03-26 13:39:39,763 : INFO : collected 82381 word types and 9 unique tags from a corpus of 12567 examples and 5741909 words\n",
      "2019-03-26 13:39:39,764 : INFO : Loading a fresh vocabulary\n",
      "2019-03-26 13:39:39,874 : INFO : effective_min_count=5 retains 33582 unique words (40% of original 82381, drops 48799)\n",
      "2019-03-26 13:39:39,875 : INFO : effective_min_count=5 leaves 5660004 word corpus (98% of original 5741909, drops 81905)\n",
      "2019-03-26 13:39:40,013 : INFO : deleting the raw counts dictionary of 82381 items\n",
      "2019-03-26 13:39:40,016 : INFO : sample=0.001 downsamples 36 most-common words\n",
      "2019-03-26 13:39:40,018 : INFO : downsampling leaves estimated 4780228 word corpus (84.5% of prior 5660004)\n",
      "2019-03-26 13:39:40,160 : INFO : estimated required memory for 33582 words and 300 dimensions: 97400400 bytes\n",
      "2019-03-26 13:39:40,161 : INFO : resetting layer weights\n",
      "2019-03-26 13:39:40,705 : INFO : training model with 11 workers on 33582 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-03-26 13:39:41,723 : INFO : EPOCH 1 - PROGRESS: at 12.57% examples, 614620 words/s, in_qsize 21, out_qsize 0\n",
      "2019-03-26 13:39:42,757 : INFO : EPOCH 1 - PROGRESS: at 26.49% examples, 632615 words/s, in_qsize 20, out_qsize 1\n",
      "2019-03-26 13:39:43,779 : INFO : EPOCH 1 - PROGRESS: at 43.54% examples, 684432 words/s, in_qsize 21, out_qsize 0\n",
      "2019-03-26 13:39:44,781 : INFO : EPOCH 1 - PROGRESS: at 59.33% examples, 703261 words/s, in_qsize 22, out_qsize 0\n",
      "2019-03-26 13:39:45,782 : INFO : EPOCH 1 - PROGRESS: at 75.94% examples, 721367 words/s, in_qsize 22, out_qsize 0\n",
      "2019-03-26 13:39:46,786 : INFO : EPOCH 1 - PROGRESS: at 93.40% examples, 737390 words/s, in_qsize 21, out_qsize 0\n",
      "2019-03-26 13:39:47,078 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2019-03-26 13:39:47,082 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-03-26 13:39:47,083 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-03-26 13:39:47,088 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-26 13:39:47,096 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-26 13:39:47,101 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-26 13:39:47,120 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-26 13:39:47,127 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-26 13:39:47,129 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-26 13:39:47,131 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-26 13:39:47,135 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-26 13:39:47,136 : INFO : EPOCH - 1 : training on 5741909 raw words (4792734 effective words) took 6.4s, 746365 effective words/s\n",
      "2019-03-26 13:39:48,146 : INFO : EPOCH 2 - PROGRESS: at 13.25% examples, 649283 words/s, in_qsize 21, out_qsize 0\n",
      "2019-03-26 13:39:49,156 : INFO : EPOCH 2 - PROGRESS: at 27.11% examples, 657419 words/s, in_qsize 22, out_qsize 0\n",
      "2019-03-26 13:39:50,175 : INFO : EPOCH 2 - PROGRESS: at 41.93% examples, 667816 words/s, in_qsize 21, out_qsize 0\n",
      "2019-03-26 13:39:51,189 : INFO : EPOCH 2 - PROGRESS: at 57.39% examples, 682814 words/s, in_qsize 21, out_qsize 0\n",
      "2019-03-26 13:39:52,204 : INFO : EPOCH 2 - PROGRESS: at 72.81% examples, 692293 words/s, in_qsize 21, out_qsize 0\n",
      "2019-03-26 13:39:53,205 : INFO : EPOCH 2 - PROGRESS: at 88.47% examples, 701349 words/s, in_qsize 22, out_qsize 0\n",
      "2019-03-26 13:39:53,774 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2019-03-26 13:39:53,780 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-03-26 13:39:53,797 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-03-26 13:39:53,798 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-26 13:39:53,801 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-26 13:39:53,808 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-26 13:39:53,829 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-26 13:39:53,832 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-26 13:39:53,833 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-26 13:39:53,836 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-26 13:39:53,841 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-26 13:39:53,842 : INFO : EPOCH - 2 : training on 5741909 raw words (4792792 effective words) took 6.7s, 715425 effective words/s\n",
      "2019-03-26 13:39:54,875 : INFO : EPOCH 3 - PROGRESS: at 13.73% examples, 658419 words/s, in_qsize 22, out_qsize 0\n",
      "2019-03-26 13:39:55,882 : INFO : EPOCH 3 - PROGRESS: at 27.77% examples, 666430 words/s, in_qsize 21, out_qsize 0\n",
      "2019-03-26 13:39:56,883 : INFO : EPOCH 3 - PROGRESS: at 43.56% examples, 691094 words/s, in_qsize 21, out_qsize 0\n",
      "2019-03-26 13:39:57,884 : INFO : EPOCH 3 - PROGRESS: at 58.41% examples, 696312 words/s, in_qsize 22, out_qsize 0\n",
      "2019-03-26 13:39:58,890 : INFO : EPOCH 3 - PROGRESS: at 74.29% examples, 708925 words/s, in_qsize 22, out_qsize 0\n",
      "2019-03-26 13:39:59,900 : INFO : EPOCH 3 - PROGRESS: at 90.21% examples, 717102 words/s, in_qsize 21, out_qsize 0\n",
      "2019-03-26 13:40:00,461 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2019-03-26 13:40:00,467 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-03-26 13:40:00,469 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-03-26 13:40:00,471 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-26 13:40:00,475 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-26 13:40:00,484 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-26 13:40:00,487 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-26 13:40:00,491 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-26 13:40:00,495 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-26 13:40:00,506 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-26 13:40:00,507 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-26 13:40:00,508 : INFO : EPOCH - 3 : training on 5741909 raw words (4792442 effective words) took 6.7s, 719628 effective words/s\n",
      "2019-03-26 13:40:01,522 : INFO : EPOCH 4 - PROGRESS: at 13.82% examples, 671737 words/s, in_qsize 21, out_qsize 0\n",
      "2019-03-26 13:40:02,525 : INFO : EPOCH 4 - PROGRESS: at 26.43% examples, 642746 words/s, in_qsize 21, out_qsize 0\n",
      "2019-03-26 13:40:03,535 : INFO : EPOCH 4 - PROGRESS: at 41.65% examples, 664904 words/s, in_qsize 20, out_qsize 1\n",
      "2019-03-26 13:40:04,537 : INFO : EPOCH 4 - PROGRESS: at 56.35% examples, 674643 words/s, in_qsize 21, out_qsize 0\n",
      "2019-03-26 13:40:05,542 : INFO : EPOCH 4 - PROGRESS: at 71.24% examples, 679901 words/s, in_qsize 21, out_qsize 0\n",
      "2019-03-26 13:40:06,550 : INFO : EPOCH 4 - PROGRESS: at 87.13% examples, 693889 words/s, in_qsize 21, out_qsize 0\n",
      "2019-03-26 13:40:07,232 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2019-03-26 13:40:07,252 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-03-26 13:40:07,254 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-03-26 13:40:07,257 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-26 13:40:07,259 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-26 13:40:07,267 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-26 13:40:07,272 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-26 13:40:07,277 : INFO : worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-26 13:40:07,278 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-26 13:40:07,291 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-26 13:40:07,295 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-26 13:40:07,296 : INFO : EPOCH - 4 : training on 5741909 raw words (4792132 effective words) took 6.8s, 706751 effective words/s\n",
      "2019-03-26 13:40:08,305 : INFO : EPOCH 5 - PROGRESS: at 13.26% examples, 648704 words/s, in_qsize 22, out_qsize 0\n",
      "2019-03-26 13:40:09,309 : INFO : EPOCH 5 - PROGRESS: at 26.42% examples, 642616 words/s, in_qsize 21, out_qsize 0\n",
      "2019-03-26 13:40:10,321 : INFO : EPOCH 5 - PROGRESS: at 43.07% examples, 686372 words/s, in_qsize 21, out_qsize 0\n",
      "2019-03-26 13:40:11,324 : INFO : EPOCH 5 - PROGRESS: at 59.65% examples, 714788 words/s, in_qsize 21, out_qsize 0\n",
      "2019-03-26 13:40:12,339 : INFO : EPOCH 5 - PROGRESS: at 75.99% examples, 725650 words/s, in_qsize 22, out_qsize 0\n",
      "2019-03-26 13:40:13,341 : INFO : EPOCH 5 - PROGRESS: at 93.81% examples, 743920 words/s, in_qsize 21, out_qsize 0\n",
      "2019-03-26 13:40:13,615 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2019-03-26 13:40:13,632 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-03-26 13:40:13,644 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-03-26 13:40:13,655 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-03-26 13:40:13,657 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-03-26 13:40:13,661 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-03-26 13:40:13,667 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-03-26 13:40:13,679 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-26 13:40:13,682 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-26 13:40:13,684 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-26 13:40:13,690 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-26 13:40:13,690 : INFO : EPOCH - 5 : training on 5741909 raw words (4792755 effective words) took 6.4s, 750151 effective words/s\n",
      "2019-03-26 13:40:13,691 : INFO : training on a 28709545 raw words (23962855 effective words) took 33.0s, 726484 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Doc2Vec(size=300, window=10, min_count=5, workers=11,alpha=0.025, min_alpha=0.025, iter=20) \n",
    "model.build_vocab(tagged_train_docs)\n",
    "model.train(tagged_train_docs, epochs=5, total_examples=model.corpus_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('에만/Josa', 0.16722562909126282),\n",
       " ('임대주택/Noun', 0.1628081500530243),\n",
       " ('준형/Noun', 0.159579336643219),\n",
       " ('역경/Noun', 0.15750226378440857),\n",
       " ('럭키/Noun', 0.15625229477882385),\n",
       " ('문자/Noun', 0.1480904519557953),\n",
       " ('고민/Noun', 0.1479140818119049),\n",
       " ('국립극단/Noun', 0.14685621857643127),\n",
       " ('비금속/Noun', 0.14632205665111542),\n",
       " ('급락/Noun', 0.14365270733833313)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectorizer.wv.most_similar('돈/Noun')\n",
    "#버전문제로 함수명 바뀜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류를 위한 피쳐 생성\n",
    "train_x = [doc_vectorizer.infer_vector(doc.words) for doc in tagged_train_docs]\n",
    "train_y = [doc.tags[0] for doc in tagged_train_docs]\n",
    "test_x = [doc_vectorizer.infer_vector(doc.words) for doc in tagged_test_docs]\n",
    "test_y = [doc.tags[0] for doc in tagged_test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=1234, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 1234) #seed number\n",
    "classifier.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4396583735610843\n"
     ]
    }
   ],
   "source": [
    "print(classifier.score(test_x,test_y))\n",
    "#Returns the mean accuracy on the given test data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },

 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
