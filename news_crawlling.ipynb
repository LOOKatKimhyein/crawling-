{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading https://files.pythonhosted.org/packages/10/ed/7e8b97591f6f456174139ec089c769f89a94a1a4025fe967691de971f314/bs4-0.0.1.tar.gz\n",
      "Collecting beautifulsoup4 (from bs4)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/5d/3260694a59df0ec52f8b4883f5d23b130bc237602a1411fa670eae12351e/beautifulsoup4-4.7.1-py3-none-any.whl (94kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 901kB/s a 0:00:011\n",
      "\u001b[?25hCollecting soupsieve>=1.2 (from beautifulsoup4->bs4)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/78/bca00cc9fa70bba1226ee70a42bf375c4e048fe69066a0d9b5e69bc2a79a/soupsieve-1.8-py2.py3-none-any.whl (88kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 13.9MB/s ta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: bs4\n",
      "  Running setup.py bdist_wheel for bs4 ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a0/b0/b2/4f80b9456b87abedbc0bf2d52235414c3467d8889be38dd472\n",
      "Successfully built bs4\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "Successfully installed beautifulsoup4-4.7.1 bs4-0.0.1 soupsieve-1.8\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "from urllib.parse import quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/hikim/text'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath(os.path.curdir) + \"/text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.curdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "https://yoonpunk.tistory.com/6\n",
    "real진짜******************************^^************************\n",
    "**조선일보, 카테고리,페이지수입력후 기사 full내용 크롤링하는 함수(1)**\n",
    "*remain : html.parser 대신 lxml\n",
    "********realreal final 2019-03-06*********\n",
    "[catogory]\n",
    "1경제             7전국\n",
    "2정치             8스포츠\n",
    "3사회             9연예\n",
    "4국제\n",
    "5문화\n",
    "6 오피니언\n",
    "'''\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "from urllib.parse import quote\n",
    "\n",
    "\n",
    "def get_text(URL, output_file):\n",
    "    source_code_from_url = urllib.request.urlopen(URL)\n",
    "    # urlllib로 news 기사 page 요청받기\n",
    "    soup = BeautifulSoup(source_code_from_url, 'html.parser')\n",
    "    soup.encoding = 'utf-8' \n",
    "    # BeautifulSoup을 통해 url로 부터 source code가져오기\n",
    "    content_of_article = soup.select('#news_body_id > div')\n",
    "    # 기사의 본문내용을 추출\n",
    "    for item in content_of_article:\n",
    "        string_item = str(item.find_all(text=True))\n",
    "\n",
    "        output_file.write(string_item)                          #\n",
    "\n",
    "##########################################################################################3\n",
    "def crawlling(page,category):\n",
    "    page = int(page)\n",
    "    output_file_name = '/content/hikim/text/{category}_page{page}.txt'.format(category=category,page=page) \n",
    "    output_file = open(output_file_name, 'w', -1,\"utf-8\")     \n",
    "    for page in range(1,page+1):\n",
    "        URL_with_page_num = 'http://news.chosun.com/svc/list_in/list.html?catid='+str(category)+'&pn='+str(page)\n",
    "        source_code_from_URL = urllib.request.urlopen(URL_with_page_num)\n",
    "        soup = BeautifulSoup(source_code_from_URL, 'html.parser')\n",
    "        soup.encoding = 'utf-8' \n",
    "\n",
    "\n",
    "        i = 1\n",
    "\n",
    "\n",
    "        for title in soup.find_all('dt'):\n",
    "            title_link = title.select('a')\n",
    "             \n",
    "            article_URL = title_link[0]['href']\n",
    "            get_text(article_URL, output_file)\n",
    "            i +=1\n",
    "\n",
    "\n",
    "    output_file.close()                                       \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    }
   ],
   "source": [
    "for cate in range(1,10):\n",
    "    crawlling(200,cate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    }
   ],
   "source": [
    "crawlling(200,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "https://yoonpunk.tistory.com/6\n",
    "\n",
    "**조선일보, 카테고리,페이지수입력후 기사 full내용 크롤링하는 함수(2)**\n",
    "크롤링결과 특수문자 \n",
    "********realreal final 2019-03-06*********\n",
    "'''\n",
    "# 특수문자 전처리\n",
    "import re\n",
    " \n",
    "# 입,출력 파일명\n",
    "\n",
    "for category in range(1,10):\n",
    "    INPUT_FILE_NAME =  '/content/hikim/text/{category}_page200.txt'.format(category=category) \n",
    "    OUTPUT_FILE_NAME =  '/content/hikim/text/{category}_page200_clean.txt'.format(category=category) \n",
    "\n",
    "    def clean_text(text):\n",
    "        cleaned_text = re.sub('[a-zA-Z]' , '', text)\n",
    "        cleaned_text = re.sub('[\\{\\}\\[\\]\\/?.,;:|\\)*~`!^\\-_+<>@\\#$%&\\\\\\=\\(\\'\\\"]','', cleaned_text)\n",
    "        return cleaned_text\n",
    "\n",
    "    # 메인 함수\n",
    "    def main():\n",
    "        read_file = open(INPUT_FILE_NAME, 'rt',encoding = 'utf-8')    \n",
    "        write_file = open(OUTPUT_FILE_NAME, 'wt', encoding = 'utf-8')\n",
    "\n",
    "        text = read_file.read()\n",
    "        text = clean_text(text)\n",
    "        write_file.write(text)\n",
    "        read_file.close()\n",
    "        write_file.close()  \n",
    "    if __name__ == \"__main__\":\n",
    "        main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/feb/final1.txt\n",
      "C:/feb/final2.txt\n",
      "C:/feb/final3.txt\n",
      "C:/feb/final4.txt\n",
      "C:/feb/final5.txt\n",
      "C:/feb/final6.txt\n",
      "C:/feb/final7.txt\n",
      "C:/feb/final8.txt\n",
      "C:/feb/final9.txt\n",
      "C:/feb/final10.txt\n"
     ]
    }
   ],
   "source": [
    "for page in range(1,11):\n",
    "    print('C:/feb/final%d.txt' % page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2_page3.txt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'2_page{i}.txt'.format(i=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
